{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 21:28:25.126396: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-30 21:28:25.148807: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-30 21:28:25.148843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-30 21:28:25.149582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-30 21:28:25.153773: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-30 21:28:25.569232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.colors import ListedColormap\n",
    "import time\n",
    "import json\n",
    "import os, argparse\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "from scipy.signal import medfilt\n",
    "import pandas as pd\n",
    "from operator import truediv\n",
    "import spectral\n",
    "import spectral.io.envi as envi\n",
    "from sklearn.decomposition import (IncrementalPCA, KernelPCA, PCA, SparsePCA,\n",
    "                                   TruncatedSVD, FactorAnalysis)\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             cohen_kappa_score, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, Conv2D, BatchNormalization, GlobalAveragePooling2D,Flatten,MaxPooling2D\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_cv_attention_models import attention_layers\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import legacy\n",
    "from keras import backend as Kb\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import (Activation, Lambda, multiply)\n",
    "from tensorflow.keras.optimizers import Adam, AdamW,SGD\n",
    "from keras.optimizers import Adam\n",
    "from operator import truediv\n",
    "import numpy as np\n",
    "from typing import List\n",
    "# print(tf.__version__)\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './datasets'\n",
    "def LoadHSIData(method):\n",
    "    data_path = os.path.join(os.getcwd(),f'{base_dir}')\n",
    "    if method == 'LK':\n",
    "        ## http://rsidea.whu.edu.cn/resource_WHUHi_sharing.htm\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'WHU_Hi_LongKou.mat'))['WHU_Hi_LongKou']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'WHU_Hi_LongKou_gt'))['WHU_Hi_LongKou_gt']\n",
    "        Num_Classes = 9\n",
    "        target_names = ['Corn', 'Cotton', 'Sesame', 'Broad-leaf soybean',\n",
    "                        'Narrow-leaf soybean', 'Rice', 'Water',\n",
    "                        'Roads and houses', 'Mixed weed']\n",
    "        \n",
    "    elif method == 'HH':\n",
    "        ## http://rsidea.whu.edu.cn/resource_WHUHi_sharing.htm\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'WHU_Hi_HongHu.mat'))['WHU_Hi_HongHu']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'WHU_Hi_HongHu_gt'))['WHU_Hi_HongHu_gt']\n",
    "        Num_Classes = 22\n",
    "        target_names = ['Red roof', 'Road', 'Bare soil', 'Cotton',\n",
    "                        'Cotton firewood', 'Rape', 'Chinese cabbage',\n",
    "                        'Pakchoi', 'Cabbage', 'Tuber mustard', 'Brassica parachinensis',\n",
    "                        'Brassica chinensis', 'Small Brassica chinensis', 'Lactuca sativa',\n",
    "                        'Celtuce', 'Film covered lettuce', 'Romaine lettuce',\n",
    "                        'Carrot', 'White radish', 'Garlic sprout', 'Broad bean',\n",
    "                        'Tree']\n",
    "        \n",
    "    elif method == 'HC':\n",
    "        ## http://rsidea.whu.edu.cn/resource_WHUHi_sharing.htm\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'WHU_Hi_HanChuan.mat'))['WHU_Hi_HanChuan']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'WHU_Hi_HanChuan_gt'))['WHU_Hi_HanChuan_gt']\n",
    "        Num_Classes = 16\n",
    "        target_names = ['Strawberry', 'Cowpea', 'Soybean', 'Sorghum',\n",
    "                        'Water spinach', 'Watermelon', 'Greens', 'Trees', 'Grass',\n",
    "                        'Red roof', 'Gray roof', 'Plastic', 'Bare soil', 'Road',\n",
    "                        'Bright object', 'Water']\n",
    "\n",
    "    elif method == 'IP':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "        Num_Classes = 16\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn',\n",
    "                        'Grass-pasture', 'Grass-trees', 'Grass-mowed',\n",
    "                        'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                        'Soybean-clean', 'Wheat', 'Woods', 'Buildings',\n",
    "                        'Stone-Steel']\n",
    "        \n",
    "    elif method == 'BS':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'Botswana.mat'))['Botswana']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'Botswana_gt.mat'))['Botswana_gt']\n",
    "        Num_Classes = 14\n",
    "        target_names = ['Water', 'Hippo Grass', 'Floodplain Grasses 1', 'Floodplain Grasses 2',\n",
    "                        'Reeds 1', 'Riparian', 'Firescar 2', 'Island Interior', 'Woodlands',\n",
    "                        'Acacia Shrublands', 'Acacia Grasslands', 'Short Mopane', 'Mixed Mopane', 'Exposed Soils']\n",
    "\n",
    "    elif method == 'KSC':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'KSC.mat'))['KSC']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'KSC_gt.mat'))['KSC_gt']\n",
    "        Num_Classes = 13\n",
    "        target_names = ['Scrub', 'Willow Swamp', 'CP/Oak', 'CP hammock', 'Slash Pine', 'Oak/Broadleaf', 'Hardwood Swamp',\n",
    "                        'Graminoid Marsh', 'Spartina Marsh', 'Cattail Marsh', 'Salt Marsh', 'Mud Flats', 'Water']\n",
    "     \n",
    "    elif method == 'PU':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "        Num_Classes = 9\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted','Soil','Bitumen',\n",
    "                        'Bricks','Shadows']\n",
    "\n",
    "    elif method == 'PC':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'Pavia.mat'))['pavia']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'Pavia_gt.mat'))['pavia_gt']\n",
    "        Num_Classes = 9\n",
    "        target_names = ['Water', 'Trees', 'Asphalt', 'Bricks', 'Bitumen', 'Tiles', 'Shadows',\n",
    "                        'Meadows', 'Soil']\n",
    "\n",
    "    elif method == 'SA':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "        Num_Classes = 16\n",
    "        target_names = ['Weeds_1','Weeds_2','Fallow',\n",
    "                        'Fallow_rough_plow','Fallow_smooth', 'Stubble','Celery',\n",
    "                        'Grapes_untrained','Soil_vinyard_develop','Corn_Weeds',\n",
    "                        'Lettuce_4wk','Lettuce_5wk','Lettuce_6wk',\n",
    "                        'Lettuce_7wk', 'Vinyard_untrained','Vinyard_trellis']\n",
    "      \n",
    "    elif method == 'SLA':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'SalinasA_corrected.mat'))['salinasA_corrected']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'SalinasA_gt.mat'))['salinasA_gt']\n",
    "        val_old = np.array([0,1,10,11,12,13,14])\n",
    "        val_new = np.array([0,1,2,3,4,5,6])\n",
    "        index = np.digitize(GT.ravel(), val_old, right=True)\n",
    "        GT = val_new[index].reshape(GT.shape)\n",
    "        Num_Classes = 6\n",
    "        target_names = ['Brocoli 1', 'Corn weeds', 'Lettuce 4wk', 'Lettuce 5wk',\n",
    "                       'Lettuce 6wk', 'Lettuce 7wk']\n",
    "\n",
    "    elif method == 'UH13':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'HU13.mat'))['HSI']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'HU13_gt.mat'))['gt']\n",
    "        Num_Classes = 15\n",
    "        target_names = ['Healthy grass', 'Stressed grass', 'Synthetic grass', 'Trees',\n",
    "                    'Soil', 'Water', 'Residential', 'Commercial', 'Road',\n",
    "                    'Highway', 'Railway', 'Parking Lot 1', 'Parking Lot 2',\n",
    "                    'Tennis Court', 'Running Track']\n",
    "\n",
    "    elif method == 'UH18':\n",
    "        HSI = sio.loadmat(os.path.join(data_path, 'HU18.mat'))['img']\n",
    "        GT = sio.loadmat(os.path.join(data_path, 'HU18_gt.mat'))['gt']\n",
    "        Num_Classes = 20\n",
    "        target_names = ['Healthy grass', 'Stressed grass', 'Artificial turf', 'Evergreen trees',\n",
    "                      'Deciduous trees', 'Bare earth', 'Water', 'Residential buildings',\n",
    "                      'Non-residential buildings', 'Roads', 'Sidewalks', 'Crosswalks',\n",
    "                      'Major thoroughfares', 'Highways', 'Railways', 'Paved parking lots',\n",
    "                      'Unpaved parking lots', 'Cars', 'Trains', 'Stadium seats']\n",
    "    else:\n",
    "        print(\"Wrong Choice\")\n",
    "\n",
    "    return HSI, GT, Num_Classes, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different Dimensional Reduction Methods\n",
    "def DLMethod(method, HSI, NC = 75):\n",
    "    RHSI = np.reshape(HSI, (-1, HSI.shape[2]))\n",
    "    if method == 'PCA': ## PCA\n",
    "        pca = PCA(n_components = NC, whiten = True)\n",
    "        RHSI = pca.fit_transform(RHSI)\n",
    "        RHSI = np.reshape(RHSI, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    elif method == 'iPCA': ## Incremental PCA\n",
    "        n_batches = 256\n",
    "        inc_pca = IncrementalPCA(n_components = NC)\n",
    "        for X_batch in np.array_split(RHSI, n_batches):\n",
    "          inc_pca.partial_fit(X_batch)\n",
    "        X_ipca = inc_pca.transform(RHSI)\n",
    "        RHSI = np.reshape(X_ipca, (HSI.shape[0], HSI.shape[1], NC))\n",
    "    return RHSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def TrTeSplit(HSI, GT, trRatio, vrRatio, teRatio, randomState=345):\n",
    "    # Split into train and test sets\n",
    "    Tr, Te, TrC, TeC = train_test_split(HSI, GT, test_size=teRatio,\n",
    "                                        random_state=randomState, stratify=GT)\n",
    "    # Calculate the validation ratio based on the updated test and train ratios\n",
    "    totalTrRatio = trRatio + vrRatio\n",
    "    new_vrRatio = vrRatio / totalTrRatio\n",
    "    # Split train set into train and validation sets\n",
    "    Tr, Va, TrC, VaC = train_test_split(Tr, TrC, test_size=new_vrRatio,\n",
    "                                        random_state=randomState, stratify=TrC)\n",
    "\n",
    "    return Tr, Va, Te, TrC, VaC, TeC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arslan/miniconda3/envs/hsi/lib/python3.10/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "HSID = \"IP\" ## \"SLA\", \"IP\", \"PU\", \"PC\", \"SA\", \"KSC\", \"BS\", \"LK\", \"HH\" (difficult to compile), \"HC\"\n",
    "DLM = \"PCA\" ## \"PCA\", \"iPCA\"\n",
    "WS = 8\n",
    "teRatio = 0.50\n",
    "trRatio = 0.50 #0.01 0.50\n",
    "vrRatio = 0.50 #0.99 0.50\n",
    "k = 15\n",
    "# adam = Adam (learning_rate= 0.0001,  weight_decay = 1e-06)\n",
    "# adam = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
    "adam = tf.keras.optimizers.legacy.Adam(lr = 0.001, decay = 1e-04)\n",
    "epochs = 50\n",
    "batch_size = 56\n",
    "output_dir = os.path.join(f\"SSFK_FKAN/{HSID}/\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creat Patches for 3D (Spatial-Spectral) Models\n",
    "def ImageCubes(HSI, GT, WS=WS, removeZeroLabels=True):\n",
    "    num_rows, num_cols, num_bands = HSI.shape\n",
    "    margin = int(WS / 2)\n",
    "    padded_data = np.pad(HSI, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
    "    image_cubes = np.zeros((num_rows * num_cols, WS, WS, num_bands))\n",
    "    patchesLabels = np.zeros((num_rows * num_cols))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, num_rows + margin):\n",
    "        for c in range(margin, num_cols + margin):\n",
    "            cube = padded_data[r - margin: r + margin, c - margin: c + margin, :]\n",
    "            image_cubes[patchIndex, :, :, :] = cube\n",
    "            patchesLabels[patchIndex] = GT[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "      image_cubes = image_cubes[patchesLabels>0,:,:,:]\n",
    "      patchesLabels = patchesLabels[patchesLabels>0]\n",
    "      patchesLabels -= 1\n",
    "    return image_cubes, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning Class Labels for Final Classification and Confusion Matrices\n",
    "def ClassificationReports(TeC, Te_Pred, target_names,zero_division=0):\n",
    "    Te_Pred = np.argmax(Te_Pred, axis=1)\n",
    "    classification = classification_report(np.argmax(TeC, axis=1), Te_Pred, target_names = target_names,zero_division=zero_division)\n",
    "    oa = accuracy_score(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    confusion = confusion_matrix(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    list_diag = np.diag(confusion)\n",
    "    list_raw_sum = np.sum(confusion, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    aa = np.mean(each_acc)\n",
    "    kappa = cohen_kappa_score(np.argmax(TeC, axis=1), Te_Pred)\n",
    "    return classification, confusion, oa*100, each_acc*100, aa*100, kappa*100\n",
    "\n",
    "## Writing Results in CSV files\n",
    "def CSVResults(file_name, classification, confusion, Tr_Time, Te_Time, DL_Time, kappa, oa, aa, each_acc):\n",
    "    classification = str(classification)\n",
    "    confusion = str(confusion)\n",
    "    with open(file_name, 'w') as CSV_file:\n",
    "      CSV_file.write('{} Tr_Time'.format(Tr_Time))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Te_Time'.format(Te_Time))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} DL_Time'.format(DL_Time))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{} Average accuracy (%)'.format(aa))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{}'.format(classification))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{}'.format(each_acc))\n",
    "      CSV_file.write('\\n')\n",
    "      CSV_file.write('{}'.format(confusion))\n",
    "    return CSV_file\n",
    "\n",
    "## Plot and Save Confusion Matrix\n",
    "def Conf_Mat(Te_Pred, TeC, target_names):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    Te_Pred = np.argmax(Te_Pred, axis=1)\n",
    "    confusion = confusion_matrix(np.argmax(TeC, axis=1), Te_Pred, labels=np.unique(np.argmax(TeC, axis=1)))\n",
    "    cm_sum = np.sum(confusion, axis=1, keepdims=True)\n",
    "    cm_perc = confusion / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(confusion).astype(str)\n",
    "    nrows, ncols = confusion.shape\n",
    "    for l in range(nrows):\n",
    "      for m in range(ncols):\n",
    "        c = confusion[l, m]\n",
    "        p = cm_perc[l, m]\n",
    "        if l == m:\n",
    "          s = cm_sum[l]\n",
    "          annot[l, m] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "        elif c == 0:\n",
    "          annot[l, m] = ''\n",
    "        else:\n",
    "          annot[l, m] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(confusion, index=np.unique(target_names), columns=np.unique(target_names))\n",
    "    return cm, annot\n",
    "  \n",
    "## Plot Ground Truths\n",
    "def GT_Plot(CRDHSI, GT, model, WS, k):\n",
    "  Predicted = model.predict(CRDHSI)\n",
    "  Predicted = np.argmax(Predicted, axis=1)\n",
    "  height, width = np.shape(GT)\n",
    "  ## Calculate the predicted Ground Truths\n",
    "  outputs = np.zeros((height, width))\n",
    "  count = 0\n",
    "  for AA in range(height):\n",
    "    for BB in range(width):\n",
    "      target = int(GT[AA,BB])\n",
    "      if target == 0:\n",
    "        continue\n",
    "      else:\n",
    "        outputs[AA][BB] = Predicted[count]\n",
    "        count = count+1\n",
    "  return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2562, 8, 8, 15, 1)\n",
      "(2562, 16)\n"
     ]
    }
   ],
   "source": [
    "HSI, GT, Num_Classes, target_names = LoadHSIData(HSID)\n",
    "## Reduce the Dimensionality\n",
    "#if k < HSI.shape[2]:\n",
    "start = time.time()\n",
    "RDHSI = DLMethod(DLM, HSI, NC = k)\n",
    "end = time.time()\n",
    "DL_Time = end - start\n",
    "## Create Image Cubes for Model Building\n",
    "CRDHSI, CGT = ImageCubes(RDHSI, GT, WS = WS)\n",
    "## Split Train/validation and Test sets\n",
    "Tr, Va, Te, TrC, VaC, TeC = TrTeSplit(CRDHSI, CGT, trRatio, vrRatio, teRatio)\n",
    "# Reshape train, validation, and test sets\n",
    "Tr = Tr.reshape(-1, WS,WS,k,1)  # Flatten input for the model\n",
    "Va = Va.reshape(-1, WS,WS,k,1)  # Flatten input for the model\n",
    "Te = Te.reshape(-1, WS,WS,k,1)  # Flatten input for the mode\n",
    "# Tr = Tr.reshape(-1, WS, WS, k, 1)\n",
    "TrC = to_categorical(TrC, num_classes=Num_Classes)\n",
    "# Va = Va.reshape(-1, WS, WS, k, 1)\n",
    "VaC = to_categorical(VaC, num_classes=Num_Classes)\n",
    "# Te = Te.reshape(-1, WS, WS, k, 1)\n",
    "TeC = to_categorical(TeC, num_classes=Num_Classes)\n",
    "print(Tr.shape)\n",
    "print(TrC.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralSpatialTokenGeneration(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels, **kwargs):\n",
    "        super(SpectralSpatialTokenGeneration, self).__init__(**kwargs)\n",
    "        self.spatial_tokens = Dense(out_channels)\n",
    "        self.spectral_tokens = Dense(out_channels)\n",
    "    def call(self, x):\n",
    "        B, H, W, C = x.shape\n",
    "        # Use tf.shape to handle dynamic batch dimension\n",
    "        spatial_tokens = self.spatial_tokens(tf.reshape(tf.transpose(x, [0, 2, 3, 1]), [tf.shape(x)[0], H * W, C]))\n",
    "        spectral_tokens = self.spectral_tokens(tf.reshape(tf.transpose(x, [0, 1, 2, 3]), [tf.shape(x)[0], H * W, C]))\n",
    "        return spatial_tokens,spectral_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineLinear(tf.keras.layers.Layer):\n",
    "    def __init__(self, in_features, out_features, init_scale=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.init_scale = init_scale\n",
    "        self.weight = self.add_weight(\n",
    "            shape=(self.out_features, self.in_features),\n",
    "            initializer=tf.keras.initializers.GlorotUniform(), #tf.keras.initializers.TruncatedNormal(mean=0.0, stddev=init_scale), #HeNormal(),\n",
    "            trainable=True,\n",
    "            regularizer=tf.keras.regularizers.l2(0.001)\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, tf.transpose(self.weight))\n",
    "    \n",
    "class RadialBasisFunction(tf.keras.layers.Layer):\n",
    "    def __init__(self, grid_min=-2.0, grid_max=2.0, num_grids=15, denominator=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.grid_min = grid_min\n",
    "        self.grid_max = grid_max\n",
    "        self.num_grids = num_grids\n",
    "        self.denominator = denominator or (grid_max - grid_min) / (num_grids - 1)\n",
    "        self.grid = tf.Variable(\n",
    "            initial_value=tf.linspace(grid_min, grid_max, num_grids),\n",
    "            trainable=False,\n",
    "            name=\"grid\"\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        expanded_inputs = tf.expand_dims(inputs, axis=-1)\n",
    "        return tf.exp(-((expanded_inputs - self.grid) / self.denominator) ** 2)\n",
    "    \n",
    "class FastKANLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 input_dim, output_dim, \n",
    "                 grid_min=-2.0, grid_max=2.0, \n",
    "                 num_grids=15, use_base_update=True, \n",
    "                 use_layernorm=True, base_activation=tf.nn.relu, \n",
    "                 spline_weight_init_scale=0.1, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.use_layernorm = use_layernorm\n",
    "        self.use_base_update = use_base_update\n",
    "        self.base_activation = base_activation\n",
    "        if use_layernorm:\n",
    "            assert input_dim > 1, \"Do not use layernorms on 1D inputs. Set `use_layernorm=False`.\"\n",
    "            self.layernorm = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "        else:\n",
    "            self.layernorm = None\n",
    "        self.rbf = RadialBasisFunction(grid_min, grid_max, num_grids)\n",
    "        self.spline_linear = SplineLinear(input_dim * num_grids, output_dim, init_scale=spline_weight_init_scale)\n",
    "        if use_base_update:\n",
    "            self.base_activation = base_activation\n",
    "            self.base_linear = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs, use_layernorm=True):\n",
    "        if self.layernorm is not None and use_layernorm:\n",
    "            normalized_inputs = self.layernorm(inputs)\n",
    "        else:\n",
    "            normalized_inputs = inputs\n",
    "        spline_basis = self.rbf(normalized_inputs)\n",
    "        spline_basis_flat = tf.reshape(\n",
    "            spline_basis,\n",
    "            shape=(-1, spline_basis.shape[-2] * spline_basis.shape[-1])\n",
    "        )\n",
    "        ret = self.spline_linear(spline_basis_flat)\n",
    "        ret = tf.reshape(ret, shape=tf.shape(inputs)) \n",
    "        # ret = tf.reshape(ret, [-1, ret.shape[-1]])  # Adjust as needed, e.g., flattening over axes\n",
    "        if self.use_base_update:\n",
    "            base = self.base_linear(self.base_activation(inputs))\n",
    "            ret = ret + base\n",
    "        return ret\n",
    "\n",
    "class FastKAN(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers_hidden: List[int],\n",
    "        grid_min =-2.0,\n",
    "        grid_max =2.0,\n",
    "        num_grids=15,\n",
    "        use_base_update = True,\n",
    "        base_activation = tf.nn.silu,\n",
    "        spline_weight_init_scale = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.kan_layers = []\n",
    "        for in_dim, out_dim in zip(layers_hidden[:-1], layers_hidden[1:]):\n",
    "            self.kan_layers.append(\n",
    "                FastKANLayer(\n",
    "                    input_dim=in_dim,\n",
    "                    output_dim=out_dim,\n",
    "                    grid_min=grid_min,\n",
    "                    grid_max=grid_max,\n",
    "                    num_grids=num_grids,\n",
    "                    use_base_update=use_base_update,\n",
    "                    base_activation=base_activation,\n",
    "                    spline_weight_init_scale=spline_weight_init_scale,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for layer in self.kan_layers:\n",
    "            # residual = x\n",
    "            x = layer(x, training=training)\n",
    "            # x = x + residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAST KAN ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHeadKANAttention(tf.keras.layers.Layer):\n",
    "#     def __init__(self, \n",
    "#                  input_dim, output_dim, num_heads, \n",
    "#                  grid_min=-2.0, grid_max=2.0, \n",
    "#                  num_grids=15, spline_weight_init_scale=0.1, \n",
    "#                  use_layernorm=True, base_activation=tf.nn.relu, \n",
    "#                  **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         assert output_dim % num_heads == 0, \"output_dim must be divisible by num_heads.\"\n",
    "#         self.output_dim = output_dim\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_dim = output_dim // num_heads\n",
    "\n",
    "#         self.query_layer = FastKANLayer(\n",
    "#             input_dim, output_dim, \n",
    "#             grid_min=grid_min, grid_max=grid_max, \n",
    "#             num_grids=num_grids, spline_weight_init_scale=spline_weight_init_scale,\n",
    "#             use_layernorm=use_layernorm, base_activation=base_activation\n",
    "#         )\n",
    "        \n",
    "#         self.key_layer = FastKANLayer(\n",
    "#             input_dim, output_dim, \n",
    "#             grid_min=grid_min, grid_max=grid_max, \n",
    "#             num_grids=num_grids, spline_weight_init_scale=spline_weight_init_scale,\n",
    "#             use_layernorm=use_layernorm, base_activation=base_activation\n",
    "#         )\n",
    "        \n",
    "#         self.value_layer = FastKANLayer(\n",
    "#             input_dim, output_dim, \n",
    "#             grid_min=grid_min, grid_max=grid_max, \n",
    "#             num_grids=num_grids, spline_weight_init_scale=spline_weight_init_scale,\n",
    "#             use_layernorm=use_layernorm, base_activation=base_activation\n",
    "#         )\n",
    "\n",
    "#         self.output_layer = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "#     def split_heads(self, x, batch_size):\n",
    "#         \"\"\"Split the input tensor into multiple heads.\"\"\"\n",
    "#         x = tf.reshape(x, (batch_size, -1, self.num_heads, self.head_dim))\n",
    "#         return tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "#     def combine_heads(self, x, batch_size):\n",
    "#         \"\"\"Combine the heads back into the original shape.\"\"\"\n",
    "#         x = tf.transpose(x, perm=[0, 2, 1, 3])  # (batch_size, seq_len, num_heads, head_dim)\n",
    "#         return tf.reshape(x, (batch_size, -1, self.output_dim))  # (batch_size, seq_len, output_dim)\n",
    "\n",
    "#     def call(self, query, key, value, mask=None):\n",
    "#         batch_size = tf.shape(query)[0]\n",
    "\n",
    "#         # Pass the query, key, and value through KAN layers\n",
    "#         query = self.query_layer(query)\n",
    "#         key = self.key_layer(key)\n",
    "#         value = self.value_layer(value)\n",
    "\n",
    "#         # Split into multiple heads\n",
    "#         query = self.split_heads(query, batch_size)  # (batch_size, num_heads, seq_len_q, head_dim)\n",
    "#         key = self.split_heads(key, batch_size)      # (batch_size, num_heads, seq_len_k, head_dim)\n",
    "#         value = self.split_heads(value, batch_size)  # (batch_size, num_heads, seq_len_v, head_dim)\n",
    "\n",
    "#         # Scaled dot-product attention using einsum\n",
    "#         attention_scores = tf.linalg.einsum('bnqd,bnkd->bnqk', query, key)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "#         attention_scores /= tf.math.sqrt(tf.cast(self.head_dim, tf.float32))\n",
    "\n",
    "#         if mask is not None:\n",
    "#             attention_scores = tf.where(mask, attention_scores, tf.fill(tf.shape(attention_scores), -1e9))\n",
    "\n",
    "#         attention_weights = tf.nn.softmax(attention_scores, axis=-1)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "\n",
    "#         # Apply attention weights to the values\n",
    "#         attention_output = tf.linalg.einsum('bnqk,bnvd->bnqv', attention_weights, value)  # (batch_size, num_heads, seq_len_q, head_dim)\n",
    "\n",
    "#         # Combine heads\n",
    "#         attention_output = self.combine_heads(attention_output, batch_size)  # (batch_size, seq_len_q, output_dim)\n",
    "\n",
    "#         # Output projection\n",
    "#         output = self.output_layer(attention_output)  # (batch_size, seq_len_q, output_dim)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadKANAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 input_dim,output_dim, num_heads, \n",
    "                 grid_min=-2.0, grid_max=2.0, \n",
    "                 num_grids=15, spline_weight_init_scale=0.1, \n",
    "                 use_layernorm=True, base_activation=tf.nn.swish, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        assert output_dim % num_heads == 0, \"embed_dim must be divisible by num_heads.\"\n",
    "        self.output_dim = output_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = output_dim // num_heads\n",
    "\n",
    "        self.query_layer = FastKANLayer(\n",
    "            input_dim, \n",
    "            output_dim,\n",
    "            grid_min=grid_min, \n",
    "            grid_max=grid_max, \n",
    "            num_grids=num_grids, \n",
    "            use_base_update=True, \n",
    "            use_layernorm=use_layernorm, \n",
    "            base_activation=base_activation, \n",
    "            spline_weight_init_scale=spline_weight_init_scale\n",
    "        )\n",
    "        self.key_layer = FastKANLayer(\n",
    "            input_dim, \n",
    "            output_dim,\n",
    "            grid_min=grid_min, \n",
    "            grid_max=grid_max, \n",
    "            num_grids=num_grids, \n",
    "            use_base_update=True, \n",
    "            use_layernorm=use_layernorm, \n",
    "            base_activation=base_activation, \n",
    "            spline_weight_init_scale=spline_weight_init_scale\n",
    "        )\n",
    "        self.value_layer = FastKANLayer(\n",
    "            input_dim, \n",
    "            output_dim,\n",
    "            grid_min=grid_min, \n",
    "            grid_max=grid_max, \n",
    "            num_grids=num_grids, \n",
    "            use_base_update=True, \n",
    "            use_layernorm=use_layernorm, \n",
    "            base_activation=base_activation, \n",
    "            spline_weight_init_scale=spline_weight_init_scale\n",
    "        )\n",
    "        self.output_layer = tf.keras.layers.Dense(output_dim)\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # Split the last dimension into (num_heads, head_dim)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.head_dim))\n",
    "        # Transpose to (batch_size, num_heads, seq_len, head_dim)\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def combine_heads(self, x, batch_size):\n",
    "        # Transpose to (batch_size, seq_len, num_heads, head_dim)\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        # Combine the last two dimensions to return to (batch_size, seq_len, embed_dim)\n",
    "        return tf.reshape(x, (batch_size, -1, self.output_dim))\n",
    "    def call(self, query, key, value, mask=None):\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        # Pass through KAN layers\n",
    "        query = self.query_layer(query)\n",
    "        key = self.key_layer(key)\n",
    "        value = self.value_layer(value)\n",
    "        # Split heads for multi-head attention\n",
    "        query = self.split_heads(query, batch_size)  # (batch_size, num_heads, seq_len_q, head_dim)\n",
    "        key = self.split_heads(key, batch_size)      # (batch_size, num_heads, seq_len_k, head_dim)\n",
    "        value = self.split_heads(value, batch_size)  # (batch_size, num_heads, seq_len_v, head_dim)\n",
    "        # Scaled dot-product attention\n",
    "        attention_scores = tf.matmul(query, key, transpose_b=True)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        attention_scores /= tf.math.sqrt(tf.cast(self.head_dim, tf.float32))\n",
    "        if mask is not None:\n",
    "            attention_scores += (mask * -1e9)  # Apply mask (optional)\n",
    "        attention_weights = tf.nn.softmax(attention_scores, axis=-1)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        attention_output = tf.matmul(attention_weights, value)  # (batch_size, num_heads, seq_len_q, head_dim)\n",
    "        # Combine heads\n",
    "        attention_output = self.combine_heads(attention_output, batch_size)  # (batch_size, seq_len_q, embed_dim)\n",
    "        # Final dense layer\n",
    "        output = self.output_layer(attention_output)  # (batch_size, seq_len_q, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHeadKANAttention(tf.keras.layers.Layer):\n",
    "#     def __init__(self, \n",
    "#                  input_dim, \n",
    "#                  num_heads, \n",
    "#                  output_dim, \n",
    "#                  grid_min=-2.0, \n",
    "#                  grid_max=2.0, \n",
    "#                  num_grids=25, \n",
    "#                  use_base_update=True, \n",
    "#                  use_layernorm=True, \n",
    "#                  base_activation=tf.nn.swish, \n",
    "#                  spline_weight_init_scale=0.1, \n",
    "#                  **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         assert output_dim % num_heads == 0, \"Output dimension must be divisible by the number of heads.\"\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_dim = output_dim // num_heads\n",
    "\n",
    "#         # Query, Key, and Value projections\n",
    "#         self.query_kan = FastKANLayer(input_dim, output_dim, grid_min, grid_max, num_grids, use_base_update, use_layernorm, base_activation, spline_weight_init_scale)\n",
    "#         self.key_kan = FastKANLayer(input_dim, output_dim, grid_min, grid_max, num_grids, use_base_update, use_layernorm, base_activation, spline_weight_init_scale)\n",
    "#         self.value_kan = FastKANLayer(input_dim, output_dim, grid_min, grid_max, num_grids, use_base_update, use_layernorm, base_activation, spline_weight_init_scale)\n",
    "\n",
    "#         # Final output projection\n",
    "#         self.output_projection = tf.keras.layers.Dense(output_dim)\n",
    "\n",
    "#     def split_heads(self, x, batch_size):\n",
    "#         # Split the last dimension into (num_heads, head_dim)\n",
    "#         x = tf.reshape(x, (batch_size, -1, self.num_heads, self.head_dim))\n",
    "#         # Transpose for shape (batch_size, num_heads, seq_len, head_dim)\n",
    "#         return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "#     def combine_heads(self, x):\n",
    "#         # Transpose and reshape back to (batch_size, seq_len, output_dim)\n",
    "#         x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "#         return tf.reshape(x, (tf.shape(x)[0], -1, self.num_heads * self.head_dim))\n",
    "\n",
    "#     def call(self, queries, keys, values):\n",
    "#         batch_size = tf.shape(queries)[0]\n",
    "\n",
    "#         # Compute Q, K, V using FastKANLayer\n",
    "#         Q = self.query_kan(queries)\n",
    "#         K = self.key_kan(keys)\n",
    "#         V = self.value_kan(values)\n",
    "\n",
    "#         # Split heads\n",
    "#         Q = self.split_heads(Q, batch_size)\n",
    "#         K = self.split_heads(K, batch_size)\n",
    "#         V = self.split_heads(V, batch_size)\n",
    "\n",
    "#         # Scaled dot-product attention (modified to include KAN-based similarity)\n",
    "#         attention_scores = tf.matmul(Q, K, transpose_b=True)\n",
    "#         attention_scores /= tf.math.sqrt(tf.cast(self.head_dim, tf.float32))\n",
    "#         attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n",
    "\n",
    "#         # Weighted sum of values\n",
    "#         attention_output = tf.matmul(attention_weights, V)\n",
    "\n",
    "#         # Combine heads\n",
    "#         attention_output = self.combine_heads(attention_output)\n",
    "\n",
    "#         # Final output projection\n",
    "#         output = self.output_projection(attention_output)\n",
    "\n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpectralSpatialFeatureEnhancement(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels, **kwargs):\n",
    "        super(SpectralSpatialFeatureEnhancement, self).__init__(**kwargs)\n",
    "        # FastKAN layers for spatial and spectral gates\n",
    "        self.spatial_gate = FastKANLayer(\n",
    "            input_dim=out_channels,\n",
    "            output_dim=out_channels,\n",
    "            grid_min=-2.0,\n",
    "            grid_max=2.0,\n",
    "            num_grids=15,\n",
    "            use_base_update=True,\n",
    "            base_activation=tf.nn.relu,\n",
    "            spline_weight_init_scale=0.1\n",
    "        )\n",
    "        self.spectral_gate = FastKANLayer(\n",
    "            input_dim=out_channels,\n",
    "            output_dim=out_channels,\n",
    "            grid_min=-2.0,\n",
    "            grid_max=2.0,\n",
    "            num_grids=15,\n",
    "            use_base_update=True,\n",
    "            base_activation=tf.nn.relu,\n",
    "            spline_weight_init_scale=0.1\n",
    "        )\n",
    "        # Normalization layers\n",
    "        self.norm_spatial = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "        self.norm_spectral = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "\n",
    "    def call(self, spatial_tokens, spectral_tokens, center_tokens):\n",
    "        # Use center_tokens to enhance spatial and spectral tokens\n",
    "        spatial_enhanced = self.spatial_gate(center_tokens)\n",
    "        spectral_enhanced = self.spectral_gate(center_tokens)\n",
    "        # Normalize enhanced outputs\n",
    "        spatial_enhanced = self.norm_spatial(spatial_enhanced)\n",
    "        spectral_enhanced = self.norm_spectral(spectral_enhanced)\n",
    "        # Perform element-wise gating with residual connections\n",
    "        spatial_enhanced = spatial_tokens * spatial_enhanced + spatial_tokens\n",
    "        spectral_enhanced = spectral_tokens * spectral_enhanced + spectral_tokens\n",
    "        return spatial_enhanced, spectral_enhanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateSpaceModel(tf.keras.layers.Layer):\n",
    "    def __init__(self, state_dim, **kwargs):\n",
    "        super(StateSpaceModel, self).__init__(**kwargs)\n",
    "        self.state_dim = state_dim\n",
    "        self.state_transition = Dense(units=state_dim, activation=\"relu\")\n",
    "        self.state_update = Dense(units=state_dim, activation=\"relu\")\n",
    "    def call(self, x):\n",
    "        state = tf.zeros([tf.shape(x)[0], self.state_dim])\n",
    "        for t in range(tf.shape(x)[1]):\n",
    "            # Flatten the input if it has more than 2 dimensions\n",
    "            input_t = tf.reshape(x[:, t, :], [tf.shape(x)[0], -1])\n",
    "            state = self.state_transition(state) + self.state_update(input_t)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SSFKSMambaModel(tf.keras.Model):\n",
    "    def __init__(self, out_channels=64, state_dim=128, num_heads=8, num_grids=25, **kwargs):\n",
    "        super(SSFKSMambaModel, self).__init__(**kwargs)\n",
    "        # Tokenization\n",
    "        self.token_generation = SpectralSpatialTokenGeneration(out_channels)\n",
    "        # Multi-Head Attention\n",
    "        self.multi_head_attention = MultiHeadKANAttention(\n",
    "            input_dim=out_channels,\n",
    "            output_dim=out_channels,\n",
    "            num_heads=num_heads,  \n",
    "            grid_min=-2.0,\n",
    "            grid_max=2.0,\n",
    "            num_grids=num_grids,\n",
    "        )\n",
    "        # Feature Enhancement\n",
    "        self.feature_enhancement = SpectralSpatialFeatureEnhancement(out_channels)\n",
    "        # State Space Model using Transformer\n",
    "        self.state_space_model = StateSpaceModel(state_dim)\n",
    "        # Dense Layers and Classification\n",
    "        self.dense = tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.001))\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.classifier = tf.keras.layers.Dense(Num_Classes, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # Step 1: Tokenization\n",
    "        spatial_tokens, spectral_tokens = self.token_generation(x)\n",
    "        center_tokens = spatial_tokens[:, x.shape[1] // 2, :]  # Center tokens for gating\n",
    "        # Step 2: Feature Enhancement\n",
    "        spatial_enhanced, spectral_enhanced = self.feature_enhancement(spatial_tokens, spectral_tokens, center_tokens)\n",
    "        # Step 3: Apply Multi-Head Attention\n",
    "        spatial_attention = self.multi_head_attention(spatial_enhanced)\n",
    "        spectral_attention = self.multi_head_attention(spectral_enhanced)\n",
    "        # Step 4: Combine the outputs\n",
    "        combined_output = tf.concat([spatial_attention, spectral_attention], axis=-1)\n",
    "        # Step 5: State Space Modeling using Transformer\n",
    "        state_output = self.state_space_model(combined_output)\n",
    "        # Step 6: Dense layer and classification\n",
    "        output = self.classifier(state_output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def FastKanMamba(Tr, batch_size):\n",
    "    model = SSFKSMambaModel(\n",
    "        out_channels=64,\n",
    "        state_dim=128,\n",
    "        num_heads=4,\n",
    "    #    num_layers=4,\n",
    "        num_grids=15,\n",
    "    )\n",
    "    # Build the model by passing a batch of data\n",
    "    _ = model(Tr[:batch_size])  # Ensures model is built correctly\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN3D(WS, k, Num_Classes):\n",
    "    input_layer = Input((WS, WS, k, 1))\n",
    "    conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 7), padding = 'same', activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 5), padding = 'same', activation='relu')(conv_layer1)\n",
    "    conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), padding = 'same', activation='relu')(conv_layer2)\n",
    "    conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 3), padding = 'same', activation='relu')(conv_layer3)\n",
    "    flatten_layer = Flatten()(conv_layer4)\n",
    "    dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
    "    dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
    "    output_layer = Dense(units = Num_Classes, activation='softmax')(dense_layer2)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='CNN3D')\n",
    "    return model\n",
    "def CNN2D(WS, k, Num_Classes):\n",
    "    input_layer = Input((WS, WS, k))\n",
    "    conv_layer1 = Conv2D(filters=8, kernel_size=(3, 3), padding = 'same', activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv2D(filters=16, kernel_size=(3, 3), padding = 'same', activation='relu')(conv_layer1)\n",
    "    conv_layer3 = Conv2D(filters=32, kernel_size=(3, 3), padding = 'same', activation='relu')(conv_layer2)\n",
    "    conv_layer4 = Conv2D(filters=64, kernel_size=(3, 3), padding = 'same', activation='relu')(conv_layer3)\n",
    "    flatten_layer = Flatten()(conv_layer4)\n",
    "    dense_layer1 = Dense(units=256, activation='relu')(flatten_layer)\n",
    "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    dense_layer2 = Dense(units=128, activation='relu')(dense_layer1)\n",
    "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    output_layer = Dense(units=Num_Classes, activation='softmax')(dense_layer2)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='CNN2D')\n",
    "    return model\n",
    "def IN2D(WS, k,Num_Classes):\n",
    "    input_img = Input(shape=(WS, WS, k))\n",
    "    ## Block 1\n",
    "    layer_1 = Conv2D(30, (1, 1), padding = 'same', activation = 'relu')(input_img)\n",
    "    layer_1 = Conv2D(20, (1, 1), padding = 'same', activation = 'relu')(layer_1)\n",
    "    layer_1 = Conv2D(10, (3, 3), padding = 'same', activation = 'relu')(layer_1)\n",
    "    ## Block 2\n",
    "    layer_2 = Conv2D(40, (1, 1), padding = 'same', activation = 'relu')(input_img)\n",
    "    layer_2 = Conv2D(20, (1, 1), padding = 'same', activation = 'relu')(layer_2)\n",
    "    layer_2 = Conv2D(10, (5, 5), padding = 'same', activation = 'relu')(layer_2)\n",
    "    ## Block 3\n",
    "    layer_3 = MaxPooling2D((3, 3), strides = (1, 1), padding = 'same')(input_img)\n",
    "    layer_3 = Conv2D(20, (1, 1), padding = 'same', activation = 'relu')(layer_3)\n",
    "    layer_3 = Conv2D(10, (1, 1), padding = 'same', activation = 'relu')(layer_3)\n",
    "    ## Concatination\n",
    "    mid_1 = keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)\n",
    "    ## Convolution\n",
    "    layer_4 = Conv2D(128, (1, 1), activation = 'relu')(mid_1)\n",
    "    ## Classification Module\n",
    "    flat_1 = Flatten()(layer_4)\n",
    "    dense_1 = Dense(1200, activation = 'relu')(flat_1)\n",
    "    dense_2 = Dense(600, activation = 'relu')(dense_1)\n",
    "    dense_3 = Dense(150, activation = 'relu')(dense_2)\n",
    "    output = Dense(Num_Classes, activation = 'softmax')(dense_3)\n",
    "    ## Medel\n",
    "    model = Model([input_img], output, name='IN2D')\n",
    "    return model\n",
    "\n",
    "\n",
    "# **3D inception Net**\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "def IN3D(WS, k,Num_Classes):\n",
    "    input_img = Input(shape=(WS, WS, k, 1))\n",
    "    ## Block 1\n",
    "    layer_1 = Conv3D(30, (5, 5, 7), padding = 'same', activation='relu')(input_img)\n",
    "    layer_1 = Conv3D(20, (3, 3, 5), padding = 'same', activation='relu')(layer_1)\n",
    "    layer_1 = Conv3D(10, (3, 3, 3), padding = 'same', activation='relu')(layer_1)\n",
    "    ## Block 2\n",
    "    layer_2 = Conv3D(40, (5, 5, 7), padding = 'same', activation='relu')(input_img)\n",
    "    layer_2 = Conv3D(20, (3, 3, 5), padding = 'same', activation='relu')(layer_2)\n",
    "    layer_2 = Conv3D(10, (3, 3, 3), padding = 'same', activation='relu')(layer_2)\n",
    "    ## Block 3\n",
    "    layer_3 = Conv3D(60, (5, 5, 7), padding = 'same', activation='relu')(input_img)\n",
    "    layer_3 = Conv3D(30, (3, 3, 5), padding = 'same', activation='relu')(layer_3)\n",
    "    layer_3 = Conv3D(10, (3, 3, 3), padding = 'same', activation='relu')(layer_3)\n",
    "    ## Concatination\n",
    "    mid_1 = keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)\n",
    "    ## Convolution\n",
    "    layer_4 = Conv3D(128, (1, 1, 1), activation = 'relu')(mid_1)\n",
    "    ## Classification Module\n",
    "    flat_1 = Flatten()(layer_4)\n",
    "    dense_1 = Dense(512, activation='relu')(flat_1)\n",
    "    dense_1 = Dropout(0.4)(dense_1)\n",
    "    dense_2 = Dense(128, activation='relu')(dense_1)\n",
    "    dense_2 = Dropout(0.4)(dense_2)\n",
    "    dense_3 = Dense(64, activation='relu')(dense_2)\n",
    "    dense_3 = Dropout(0.4)(dense_3)\n",
    "    output = Dense(Num_Classes, activation='softmax')(dense_3)\n",
    "    model = Model([input_img], output, name='IN3D')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_name, Tr, TrC, Va, VaC, Te, TeC, adam, CRDHSI, HSID, teRatio, k, WS, DLM, RDHSI, GT,batch_size,epochs,output_dir):\n",
    "    print(f'Model Name : {model_name}')\n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = os.path.join(output_dir, \"\") + model_name.__name__\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(model_name.__name__)\n",
    "\n",
    "    if model_name == FastKanMamba:\n",
    "        Tr = Tr.reshape(-1, WS,WS,k)  # Flatten input for the model\n",
    "        Va = Va.reshape(-1, WS,WS,k)  # Flatten input for the model\n",
    "        Te = Te.reshape(-1, WS,WS,k) \n",
    "        model = FastKanMamba(Tr, batch_size)\n",
    "    else:\n",
    "        model = model_name(WS,k,Num_Classes)\n",
    "    file_name = f\"{HSID}_{teRatio}_{vrRatio}_{k}_{WS}_{DLM}_model_summary_of_{model_name.__name__}.txt\"\n",
    "    # Assuming `model` is your Keras model\n",
    "    total_params = model.count_params()\n",
    "    with open(os.path.join(output_dir, file_name),'w') as fh:\n",
    "        # Pass the file handle in as a lambda function to make it callable\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    # Compiling the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    # Training the model\n",
    "    start = time.time()\n",
    "    history = model.fit(x=Tr, y=TrC, batch_size=batch_size, epochs=epochs, validation_data=(Va, VaC))\n",
    "    end = time.time()\n",
    "    Tr_Time = end - start\n",
    "    start = time.time()\n",
    "    Te_Pre = model.predict(Te)\n",
    "    end = time.time()\n",
    "    Te_Time = end - start\n",
    "    ## Classification Report for Test Model\n",
    "    classification,Confusion,OA,Per_Class,AA,Kappa = ClassificationReports(TeC, Te_Pre, target_names,zero_division=0)\n",
    "    Te_Kappa = round(Kappa, 4)\n",
    "    #Writing Results in CSV File\n",
    "    file_name = os.path.join(output_dir,f\"{HSID}_{teRatio}_{vrRatio}_{k}_{WS}_{DLM}_{batch_size}_Classification_Report.csv\")\n",
    "    CSV_file = CSVResults(file_name, classification, Confusion, Tr_Time, Te_Time, DL_Time, Kappa, OA, AA, Per_Class)\n",
    "    print(classification)\n",
    "    # files.download(file_name)\n",
    "    # Ground Truths\n",
    "    outputs = GT_Plot(CRDHSI, GT, model, WS, k)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(outputs, cmap='nipy_spectral')\n",
    "    plt.axis('off')\n",
    "    file_name = f\"{HSID}_{teRatio}_{vrRatio}_{k}_{WS}_{DLM}_{batch_size}_Ground_Truths.png\"\n",
    "    plt.savefig(os.path.join(output_dir, file_name), dpi=500,format='png', bbox_inches='tight', pad_inches=0)\n",
    "    return history,Tr_Time, Te_Time, OA, AA,Kappa,total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : <function FastKanMamba at 0x7f8e09a8b640>\n",
      "FastKanMamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 21:29:20.709610: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: required broadcastable shapes\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'spectral_spatial_feature_enhancement_1' (type SpectralSpatialFeatureEnhancement).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:Mul] name: \n\nCall arguments received by layer 'spectral_spatial_feature_enhancement_1' (type SpectralSpatialFeatureEnhancement):\n  • spatial_tokens=tf.Tensor(shape=(56, 64, 64), dtype=float32)\n  • spectral_tokens=tf.Tensor(shape=(56, 64, 64), dtype=float32)\n  • center_tokens=tf.Tensor(shape=(56, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m Te_Time_list\u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_names:\n\u001b[0;32m----> 9\u001b[0m   history, Tr_Time, Te_Time, OA, AA,Kappa,total_params \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVaC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTeC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43madam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCRDHSI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHSID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mDLM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRDHSI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m   history_list\u001b[38;5;241m.\u001b[39mappend(history)\n\u001b[1;32m     13\u001b[0m   Tr_Time_list\u001b[38;5;241m.\u001b[39mappend(Tr_Time)\n",
      "Cell \u001b[0;32mIn[22], line 12\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model_name, Tr, TrC, Va, VaC, Te, TeC, adam, CRDHSI, HSID, teRatio, k, WS, DLM, RDHSI, GT, batch_size, epochs, output_dir)\u001b[0m\n\u001b[1;32m     10\u001b[0m     Va \u001b[38;5;241m=\u001b[39m Va\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, WS,WS,k)  \u001b[38;5;66;03m# Flatten input for the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     Te \u001b[38;5;241m=\u001b[39m Te\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, WS,WS,k) \n\u001b[0;32m---> 12\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mFastKanMamba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_name(WS,k,Num_Classes)\n",
      "Cell \u001b[0;32mIn[20], line 51\u001b[0m, in \u001b[0;36mFastKanMamba\u001b[0;34m(Tr, batch_size)\u001b[0m\n\u001b[1;32m     43\u001b[0m model \u001b[38;5;241m=\u001b[39m SSFKSMambaModel(\n\u001b[1;32m     44\u001b[0m     out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     45\u001b[0m     state_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     num_grids\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Build the model by passing a batch of data\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensures model is built correctly\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/hsi/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[20], line 29\u001b[0m, in \u001b[0;36mSSFKSMambaModel.call\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     27\u001b[0m center_tokens \u001b[38;5;241m=\u001b[39m spatial_tokens[:, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, :]  \u001b[38;5;66;03m# Center tokens for gating\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Step 2: Feature Enhancement\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m spatial_enhanced, spectral_enhanced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_enhancement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspatial_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectral_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Step 3: Apply Multi-Head Attention\u001b[39;00m\n\u001b[1;32m     31\u001b[0m spatial_attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_head_attention(spatial_enhanced)\n",
      "Cell \u001b[0;32mIn[14], line 37\u001b[0m, in \u001b[0;36mSpectralSpatialFeatureEnhancement.call\u001b[0;34m(self, spatial_tokens, spectral_tokens, center_tokens)\u001b[0m\n\u001b[1;32m     35\u001b[0m spectral_enhanced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_spectral(spectral_enhanced)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Perform element-wise gating with residual connections\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m spatial_enhanced \u001b[38;5;241m=\u001b[39m \u001b[43mspatial_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspatial_enhanced\u001b[49m \u001b[38;5;241m+\u001b[39m spatial_tokens\n\u001b[1;32m     38\u001b[0m spectral_enhanced \u001b[38;5;241m=\u001b[39m spectral_tokens \u001b[38;5;241m*\u001b[39m spectral_enhanced \u001b[38;5;241m+\u001b[39m spectral_tokens\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spatial_enhanced, spectral_enhanced\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'spectral_spatial_feature_enhancement_1' (type SpectralSpatialFeatureEnhancement).\n\n{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:Mul] name: \n\nCall arguments received by layer 'spectral_spatial_feature_enhancement_1' (type SpectralSpatialFeatureEnhancement):\n  • spatial_tokens=tf.Tensor(shape=(56, 64, 64), dtype=float32)\n  • spectral_tokens=tf.Tensor(shape=(56, 64, 64), dtype=float32)\n  • center_tokens=tf.Tensor(shape=(56, 64), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# model_names = [FastKanMamba,IN2D,IN3D,HybIN]\n",
    "model_names = [FastKanMamba] #[CNN2D,IN2D,FastKanMamba] #[FastKanMambaWithAttention,FastKanMamba]\n",
    "all_results = {}\n",
    "history_list = []\n",
    "Tr_Time_list= []\n",
    "Te_Time_list= []\n",
    "\n",
    "for model_name in model_names:\n",
    "  history, Tr_Time, Te_Time, OA, AA,Kappa,total_params = train_and_evaluate_model(model_name, Tr, TrC, Va, VaC, Te, TeC,\n",
    "                                       adam, CRDHSI, HSID, teRatio, k, WS,\n",
    "                                       DLM, RDHSI, GT, batch_size,epochs,output_dir)\n",
    "  history_list.append(history)\n",
    "  Tr_Time_list.append(Tr_Time)\n",
    "  Tr_Time_list.append(Te_Time)\n",
    "  \n",
    "  model_function_name = model_name.__name__\n",
    "  all_results[model_function_name] = {\n",
    "        \"history\": history.history,\n",
    "        \"Tr_Time\": Tr_Time,\n",
    "        \"Te_Time\": Te_Time,\n",
    "        \"Overall Accuracy\": OA,\n",
    "        \"Average Accuracy\": AA,\n",
    "        \"Kappa\": Kappa,\n",
    "        \"Training Parameters\": total_params\n",
    "    }\n",
    "  \n",
    "# Define the filename for all results\n",
    "all_results_filename = \"all_models_results.json\"\n",
    "\n",
    "# Concatenate output_dir with the filename\n",
    "all_results_output_path = os.path.join(output_dir, all_results_filename)\n",
    "\n",
    "# Convert the dictionary to JSON format\n",
    "json_data = json.dumps(all_results, indent=4)\n",
    "\n",
    "# Optionally, write the JSON data to a file\n",
    "with open(all_results_output_path, 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss and accuracy for each model\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "colors = ['blue','brown', 'gray', 'green', 'purple', 'orange', 'red']\n",
    "\n",
    "for i, history in enumerate(history_list):\n",
    "    # Plot loss\n",
    "    axs[0].plot(history.history['loss'], label=f'{model_names[i].__name__} Train', color=colors[i])\n",
    "    axs[0].plot(history.history['val_loss'], label=f'{model_names[i].__name__} Val', color=colors[i], linestyle='--')\n",
    "    # Plot accuracy\n",
    "    axs[1].plot(history.history['accuracy'], label=f'{model_names[i].__name__} Train', color=colors[i])\n",
    "    axs[1].plot(history.history['val_accuracy'], label=f'{model_names[i].__name__} Val', color=colors[i], linestyle='--')\n",
    "axs[0].set_title('Loss', fontsize=10)\n",
    "axs[0].set_xlabel('Epoch', fontsize=10)\n",
    "axs[1].set_title('Accuracy', fontsize=10)\n",
    "axs[1].set_xlabel('Epoch', fontsize=10)\n",
    "axs[1].legend(fontsize=6)\n",
    "axs[0].grid(True)\n",
    "axs[1].grid(True)\n",
    "plt.tight_layout()\n",
    "file_name = f\"{HSID}_{teRatio}_{k}_{WS}_{DLM}_acc_loss_curve_all_models.png\"\n",
    "plt.savefig(os.path.join(output_dir, file_name), dpi=500, format='png', bbox_inches='tight', pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
